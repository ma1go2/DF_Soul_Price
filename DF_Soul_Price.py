#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import requests
import json
from urllib.parse import quote
import time
from datetime import datetime
import pandas as pd
import os

# ğŸ”‘ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
with open("config.json", "r", encoding="utf-8") as f:
    config = json.load(f)
    API_KEY = config["API_KEY"]

# ğŸ“ì €ì¥ í´ë” ìœ„ì¹˜
path = r"C:\Users\mangg\Documents\jupyternotebook\D&F\csvì €ì¥/".replace('\\','\\\\')
    
# ğŸ” ëª¨ë‹ˆí„°ë§í•  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
ITEM_LIST = [
    'ë ˆì–´ ì†Œìš¸ ê²°ì •',
    'ìœ ë‹ˆí¬ ì†Œìš¸ ê²°ì •',
    'ë ˆì „ë”ë¦¬ ì†Œìš¸ ê²°ì •',
    'ì—í”½ ì†Œìš¸ ê²°ì •',
    'íƒœì´ˆ ì†Œìš¸ ê²°ì •'
]

# âš™ï¸ ê²€ìƒ‰ ì¡°ê±´
limit = 150
wordType = 'match'
wordShort = 'true'

# ğŸ“¦ ê²½ë§¤ì¥ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def fetch_auction_data(item_name):
    itemName = quote(item_name)
    url = (
        f"https://api.neople.co.kr/df/auction?"
        f"itemName={itemName}&limit={limit}&wordType={wordType}"
        f"&wordShort={wordShort}&sort=unitPrice:asc&apikey={API_KEY}"
    )

    response = requests.get(url)
    if response.status_code != 200:
        print(f"âŒ API ì˜¤ë¥˜ ({item_name}): {response.status_code}")
        return pd.DataFrame()

    rows = response.json().get("rows", [])
    now = datetime.now().strftime("%Y-%m-%d %H:%M")

    df = pd.DataFrame([{
        'ì¡°íšŒì‹œê°„': now,
        'ë“±ë¡ë„˜ë²„': row['auctionNo'],
        'ì•„ì´í…œëª…': row['itemName'],
        'ê°€ê²©': row['unitPrice'],
        'ìˆ˜ëŸ‰': row['count'],
        'ì‹œì„¸': row['averagePrice'],
        'ë“±ë¡ì¼ì': pd.to_datetime(row['regDate']).strftime("%Y-%m-%d %H:%M")
    } for row in rows])

    return df

# ğŸ“„ ì €ì¥ í•¨ìˆ˜ (ì¼ìë³„ íŒŒì¼ ìƒì„±, ì¤‘ë³µ ì œê±°)
def save_to_csv(new_df, item_name, path):
    # ì €ì¥ íŒŒì¼ëª… ì˜ˆ: auction_ë ˆì–´ ì†Œìš¸ ê²°ì •_2025-06-30.csv
    date_str = datetime.now().strftime("%Y-%m-%d")
    safe_item_name = item_name.replace(" ", "_")
    filename = path+f"{safe_item_name}_{date_str}.csv"

    if os.path.exists(filename):
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        old_df = pd.read_csv(filename, encoding="utf-8-sig")
        
        # ì¤‘ë³µ ë¹„êµë¥¼ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì •ìˆ˜ overflow ë°©ì§€)
        old_ids = set(old_df["ë“±ë¡ë„˜ë²„"].astype(str))
        new_unique_df = new_df[~new_df["ë“±ë¡ë„˜ë²„"].astype(str).isin(old_ids)]
        
        if not new_unique_df.empty:
            combined_df = pd.concat([old_df, new_unique_df], ignore_index=True)
            combined_df.to_csv(filename, index=False, encoding="utf-8-sig")
            print(f"âœ… {item_name}: {len(new_unique_df)}ê±´ ìƒˆë¡œ ì¶”ê°€ë¨ â†’ ì´ {len(combined_df)}ê±´")
        else:
            print(f"ğŸŸ¡ {item_name}: ì¶”ê°€ëœ í•­ëª© ì—†ìŒ (ì¤‘ë³µ)")
        
    else:
        # ì²« ì €ì¥
        new_df.to_csv(filename, index=False, encoding="utf-8-sig")
        print(f"âœ… {item_name}: {len(new_df)}ê±´ ì €ì¥ (ì‹ ê·œ íŒŒì¼ ìƒì„±)")

# ğŸ” ì£¼ê¸°ì  ì‹¤í–‰
while True:
    print(datetime.now().strftime("%Y-%m-%d %H:%M"))
    try:
        for item in ITEM_LIST:
            df = fetch_auction_data(item)
            if not df.empty:
                save_to_csv(df, item, path)
    except Exception as e:
        print("âš ï¸ ì˜ˆì™¸ ë°œìƒ:", e)

    time.sleep(60)  # 1ë¶„ ëŒ€ê¸°

